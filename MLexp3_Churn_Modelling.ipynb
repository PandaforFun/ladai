{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPWizIP7W4WocB2dJ/G5etI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"cYgUdJfGzmSc","executionInfo":{"status":"ok","timestamp":1731231501690,"user_tz":-330,"elapsed":11492,"user":{"displayName":"Rishav","userId":"08806257992787634035"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f27fcf62-8fd3-4144-d1c7-9ad3915bdf19"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7710 - loss: 0.5053\n","Epoch 2/10\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8328 - loss: 0.3976\n","Epoch 3/10\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8527 - loss: 0.3627\n","Epoch 4/10\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8509 - loss: 0.3581\n","Epoch 5/10\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8479 - loss: 0.3561\n","Epoch 6/10\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8534 - loss: 0.3432\n","Epoch 7/10\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8536 - loss: 0.3418\n","Epoch 8/10\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8598 - loss: 0.3390\n","Epoch 9/10\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8631 - loss: 0.3315\n","Epoch 10/10\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8555 - loss: 0.3344\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","Accuracy: 0.8630\n","Confusion Matrix:\n","[[1564   43]\n"," [ 231  162]]\n"]}],"source":["#importing necessary libraries\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","#loading the dataset\n","dataset = pd.read_csv(\"/content/Churn_Modelling.csv\")\n","\n","#clearing useless data from dataset\n","dataset = dataset.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n","\n","# Encoding categorical data\n","le_geography = LabelEncoder()\n","le_gender = LabelEncoder()\n","\n","dataset['Geography'] = le_geography.fit_transform(dataset['Geography'])\n","dataset['Gender'] = le_gender.fit_transform(dataset['Gender'])\n","\n","# Separating features (X) and target (y)\n","X = dataset.drop(['Exited'], axis=1)\n","y = dataset['Exited']\n","\n","# Step 3: Spliting the dataset into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Step 4: Normalizing the data\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Step 5: Initializing and building the neural network model\n","model = Sequential()\n","\n","# Input layer and first hidden layer\n","model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n","\n","# Second hidden layer\n","model.add(Dense(units=32, activation='relu'))\n","\n","# Output layer\n","model.add(Dense(units=1, activation='sigmoid'))\n","\n","# Compiling the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Training the model\n","model.fit(X_train, y_train, epochs=10, batch_size=32)\n","\n","# Step 6: Evaluating the model\n","y_pred = (model.predict(X_test) > 0.5).astype(int)\n","# Printing the accuracy score\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy:.4f}\")\n","\n","# Printing the confusion matrix\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)"]}]}