{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOU70KAj16SW674XNJ7+kZs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YS9RV02gqKG9","executionInfo":{"status":"ok","timestamp":1728836269900,"user_tz":-330,"elapsed":195254,"user":{"displayName":"Rishav","userId":"08806257992787634035"}},"outputId":"edb3d167-5b14-42f1-88d0-9426d1d866a5"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Naive Bayes Performance:\n","Accuracy: 0.9563585171281088, Precision: 0.9526290290027324, Recall: 0.9563585171281088, F1: 0.9507765656882341\n","\n","Other Models Performance:\n","SVM: {'Accuracy': 0.9541686219302362, 'Precision': 0.9526433888003272, 'Recall': 0.9541686219302362, 'F1': 0.9454740972984487}\n","Random Forest: {'Accuracy': 0.9579227279837322, 'Precision': 0.9550014617540478, 'Recall': 0.9579227279837322, 'F1': 0.9522526062728772}\n","Logistic Regression: {'Accuracy': 0.9585484123259815, 'Precision': 0.955340681299677, 'Recall': 0.9585484123259815, 'F1': 0.95359227008542}\n"]}],"source":["# Import necessary libraries\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import LabelEncoder\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","import nltk\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","url = \"https://raw.githubusercontent.com/dD2405/Twitter_Sentiment_Analysis/master/train.csv\"\n","df = pd.read_csv(url)\n","\n","# Preprocess data\n","df = df[['label', 'tweet']]\n","df['tweet'] = df['tweet'].str.lower()\n","stop_words = set(stopwords.words('english'))\n","df['tweet'] = df['tweet'].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word.isalpha() and word not in stop_words]))\n","\n","# Encode labels\n","le = LabelEncoder()\n","df['label'] = le.fit_transform(df['label'])\n","X_train, X_test, y_train, y_test = train_test_split(df['tweet'], df['label'], test_size=0.2, random_state=42)\n","\n","vectorizer = CountVectorizer()\n","X_train_vec = vectorizer.fit_transform(X_train)\n","X_test_vec = vectorizer.transform(X_test)\n","\n","# Train Naive Bayes model\n","nb = MultinomialNB()\n","nb.fit(X_train_vec, y_train)\n","y_pred_nb = nb.predict(X_test_vec)\n","\n","# Evaluate Naive Bayes\n","accuracy_nb = accuracy_score(y_test, y_pred_nb)\n","precision_nb = precision_score(y_test, y_pred_nb, average='weighted')\n","recall_nb = recall_score(y_test, y_pred_nb, average='weighted')\n","f1_nb = f1_score(y_test, y_pred_nb, average='weighted')\n","\n","# Train and evaluate other models\n","models = {\n","    'SVM': SVC(),\n","    'Random Forest': RandomForestClassifier(),\n","    'Logistic Regression': LogisticRegression(max_iter=200)\n","}\n","\n","results = {}\n","for name, model in models.items():\n","    model.fit(X_train_vec, y_train)\n","    y_pred = model.predict(X_test_vec)\n","    accuracy = accuracy_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred, average='weighted')\n","    recall = recall_score(y_test, y_pred, average='weighted')\n","    f1 = f1_score(y_test, y_pred, average='weighted')\n","    results[name] = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1': f1}\n","\n","# Output results\n","print(\"Naive Bayes Performance:\")\n","print(f\"Accuracy: {accuracy_nb}, Precision: {precision_nb}, Recall: {recall_nb}, F1: {f1_nb}\\n\")\n","print(\"Other Models Performance:\")\n","for model, scores in results.items():\n","    print(f\"{model}: {scores}\")\n"]}]}